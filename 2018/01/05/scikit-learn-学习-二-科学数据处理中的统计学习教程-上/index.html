<!DOCTYPE html>
<html lang="zh">
<head><meta name="generator" content="Hexo 3.8.0">
    <meta charset="utf-8">
    
    <title>scikit-learn 学习(二) 科学数据处理中的统计学习教程(上) | 写字的地方</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <meta name="description" content="本教程使用统计学习技术 1. 统计学习：设置, estimator 对象Datasets1234from sklearn import datasetsiris = datasets.load_iris()data = iris.datadata.shape (150, 4) 12digits = datasets.load_digits()digits.images.shape (1797, 8">
<meta name="keywords" content="scikit-learn">
<meta property="og:type" content="article">
<meta property="og:title" content="scikit-learn 学习(二) 科学数据处理中的统计学习教程(上)">
<meta property="og:url" content="http://zc119.github.io/2018/01/05/scikit-learn-学习-二-科学数据处理中的统计学习教程-上/index.html">
<meta property="og:site_name" content="写字的地方">
<meta property="og:description" content="本教程使用统计学习技术 1. 统计学习：设置, estimator 对象Datasets1234from sklearn import datasetsiris = datasets.load_iris()data = iris.datadata.shape (150, 4) 12digits = datasets.load_digits()digits.images.shape (1797, 8">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="http://zc119.github.io/image/scikit-learn/2/output_23_0.png">
<meta property="og:image" content="http://zc119.github.io/image/scikit-learn/2/output_24_0.png">
<meta property="og:image" content="http://zc119.github.io/image/scikit-learn/2/1.png">
<meta property="og:image" content="http://zc119.github.io/image/scikit-learn/2/2.png">
<meta property="og:image" content="http://zc119.github.io/image/scikit-learn/2/3.png">
<meta property="og:image" content="http://zc119.github.io/image/scikit-learn/2/4.png">
<meta property="og:image" content="http://zc119.github.io/image/scikit-learn/2/5.png">
<meta property="og:image" content="http://zc119.github.io/image/scikit-learn/2/6.png">
<meta property="og:image" content="http://zc119.github.io/image/scikit-learn/2/7.png">
<meta property="og:image" content="http://zc119.github.io/image/scikit-learn/2/8.png">
<meta property="og:image" content="http://zc119.github.io/image/scikit-learn/2/output_47_0.png">
<meta property="og:image" content="http://zc119.github.io/image/scikit-learn/2/output_47_1.png">
<meta property="og:image" content="http://zc119.github.io/image/scikit-learn/2/output_47_2.png">
<meta property="og:image" content="http://zc119.github.io/image/scikit-learn/2/9.png">
<meta property="og:image" content="http://zc119.github.io/image/scikit-learn/2/output_65_0.png">
<meta property="og:image" content="http://zc119.github.io/image/scikit-learn/2/output_76_1.png">
<meta property="og:updated_time" content="2018-01-05T09:07:11.821Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="scikit-learn 学习(二) 科学数据处理中的统计学习教程(上)">
<meta name="twitter:description" content="本教程使用统计学习技术 1. 统计学习：设置, estimator 对象Datasets1234from sklearn import datasetsiris = datasets.load_iris()data = iris.datadata.shape (150, 4) 12digits = datasets.load_digits()digits.images.shape (1797, 8">
<meta name="twitter:image" content="http://zc119.github.io/image/scikit-learn/2/output_23_0.png">
    

    
        <link rel="alternate" href="/" title="写字的地方" type="application/atom+xml">
    

    

    <link rel="stylesheet" href="/libs/font-awesome/css/font-awesome.min.css">
    <link rel="stylesheet" href="/libs/open-sans/styles.css">
    <link rel="stylesheet" href="/libs/source-code-pro/styles.css">

    <link rel="stylesheet" href="/css/style.css">

    <script src="/libs/jquery/2.1.3/jquery.min.js"></script>
    
    
        <link rel="stylesheet" href="/libs/lightgallery/css/lightgallery.min.css">
    
    
        <link rel="stylesheet" href="/libs/justified-gallery/justifiedGallery.min.css">
    
    
    
    


</head>
</html>
<body>
    <div id="container">
        <header id="header">
    <div id="header-main" class="header-inner">
        <div class="outer">
            <a href="/" id="logo">
                <i class="logo"></i>
                <span class="site-title">写字的地方</span>
            </a>
            <nav id="main-nav">
                
                    <a class="main-nav-link" href="/.">Home</a>
                
                    <a class="main-nav-link" href="/archives">Archives</a>
                
                    <a class="main-nav-link" href="/categories">Categories</a>
                
                    <a class="main-nav-link" href="/tags">Tags</a>
                
                    <a class="main-nav-link" href="/about">About</a>
                
            </nav>
            
                
                <nav id="sub-nav">
                    <div class="profile" id="profile-nav">
                        <a id="profile-anchor" href="javascript:;">
                            <img class="avatar" src="/css/images/avatar.png">
                            <i class="fa fa-caret-down"></i>
                        </a>
                    </div>
                </nav>
            
            <div id="search-form-wrap">

    <form class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="搜索">
        <button type="submit" class="search-form-submit"></button>
    </form>
    <div class="ins-search">
    <div class="ins-search-mask"></div>
    <div class="ins-search-container">
        <div class="ins-input-wrapper">
            <input type="text" class="ins-search-input" placeholder="想要查找什么...">
            <span class="ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: '文章',
            PAGES: '页面',
            CATEGORIES: '分类',
            TAGS: '标签',
            UNTITLED: '(未命名)',
        },
        ROOT_URL: '/',
        CONTENT_URL: '/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>
<script src="/js/insight.js"></script>

</div>
        </div>
    </div>
    <div id="main-nav-mobile" class="header-sub header-inner">
        <table class="menu outer">
            <tr>
                
                    <td><a class="main-nav-link" href="/.">Home</a></td>
                
                    <td><a class="main-nav-link" href="/archives">Archives</a></td>
                
                    <td><a class="main-nav-link" href="/categories">Categories</a></td>
                
                    <td><a class="main-nav-link" href="/tags">Tags</a></td>
                
                    <td><a class="main-nav-link" href="/about">About</a></td>
                
                <td>
                    
    <div class="search-form">
        <input type="text" class="ins-search-input search-form-input" placeholder="搜索">
    </div>

                </td>
            </tr>
        </table>
    </div>
</header>

        <div class="outer">
            
                

<aside id="profile">
    <div class="inner profile-inner">
        <div class="base-info profile-block">
            <img id="avatar" src="/css/images/avatar.png">
            <h2 id="name">Chi Zhou</h2>
            <h3 id="title">ZJUer &amp; Learner</h3>
            <span id="location"><i class="fa fa-map-marker"></i>HangZhou, China</span>
            <a id="follow" target="_blank" href="https://github.com/ZC119/">关注我</a>
        </div>
        <div class="article-info profile-block">
            <div class="article-info-block">
                42
                <span>文章</span>
            </div>
            <div class="article-info-block">
                7
                <span>标签</span>
            </div>
        </div>
        
        <div class="profile-block social-links">
            <table>
                <tr>
                    
                    
                    <td>
                        <a href="https://github.com/ZC119/" target="_blank" title="github" class="tooltip">
                            <i class="fa fa-github"></i>
                        </a>
                    </td>
                    
                    <td>
                        <a href="/" target="_blank" title="twitter" class="tooltip">
                            <i class="fa fa-twitter"></i>
                        </a>
                    </td>
                    
                    <td>
                        <a href="/" target="_blank" title="facebook" class="tooltip">
                            <i class="fa fa-facebook"></i>
                        </a>
                    </td>
                    
                    <td>
                        <a href="/" target="_blank" title="dribbble" class="tooltip">
                            <i class="fa fa-dribbble"></i>
                        </a>
                    </td>
                    
                    <td>
                        <a href="/" target="_blank" title="rss" class="tooltip">
                            <i class="fa fa-rss"></i>
                        </a>
                    </td>
                    
                </tr>
            </table>
        </div>
        
    </div>
</aside>

            
            <section id="main"><article id="post-scikit-learn-学习-二-科学数据处理中的统计学习教程-上" class="article article-type-post" itemscope="" itemprop="blogPost">
    <div class="article-inner">
        
        
            <header class="article-header">
                
    
        <h1 class="article-title" itemprop="name">
            scikit-learn 学习(二) 科学数据处理中的统计学习教程(上)
        </h1>
    

                
                    <div class="article-meta">
                        
    <div class="article-date">
        <i class="fa fa-calendar"></i>
        <a href="/2018/01/05/scikit-learn-学习-二-科学数据处理中的统计学习教程-上/">
            <time datetime="2018-01-05T08:58:36.000Z" itemprop="datePublished">2018-01-05</time>
        </a>
    </div>


                        
    <div class="article-category">
    	<i class="fa fa-folder"></i>
        <a class="article-category-link" href="/categories/scikit-learn/">scikit-learn</a>
    </div>

                        
    <div class="article-tag">
        <i class="fa fa-tag"></i>
        <a class="tag-link" href="/tags/scikit-learn/">scikit-learn</a>
    </div>

                    </div>
                
            </header>
        
        
        <div class="article-entry" itemprop="articleBody">
        
            
            <p>本教程使用统计学习技术</p>
<h2 id="1-统计学习：设置-estimator-对象"><a href="#1-统计学习：设置-estimator-对象" class="headerlink" title="1. 统计学习：设置, estimator 对象"></a>1. 统计学习：设置, estimator 对象</h2><h3 id="Datasets"><a href="#Datasets" class="headerlink" title="Datasets"></a>Datasets</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line">iris = datasets.load_iris()</span><br><span class="line">data = iris.data</span><br><span class="line">data.shape</span><br></pre></td></tr></table></figure>
<pre><code>(150, 4)
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">digits = datasets.load_digits()</span><br><span class="line">digits.images.shape</span><br></pre></td></tr></table></figure>
<pre><code>(1797, 8, 8)
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.imshow(digits.images[<span class="number">-1</span>], cmap=plt.cm.gray_r)</span><br></pre></td></tr></table></figure>
<pre><code>&lt;matplotlib.image.AxesImage at 0x7fd41bfb1a20&gt;
</code></pre><p>为了在 scikit 中使用这个数据集,把每张 8*8 的图像转换为长度为64的向量</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data = digits.images.reshape((digits.images.shape[<span class="number">0</span>], <span class="number">-1</span>))</span><br></pre></td></tr></table></figure>
<a id="more"></a>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data[<span class="number">0</span>]</span><br></pre></td></tr></table></figure>
<pre><code>array([  0.,   0.,   5.,  13.,   9.,   1.,   0.,   0.,   0.,   0.,  13.,
        15.,  10.,  15.,   5.,   0.,   0.,   3.,  15.,   2.,   0.,  11.,
         8.,   0.,   0.,   4.,  12.,   0.,   0.,   8.,   8.,   0.,   0.,
         5.,   8.,   0.,   0.,   9.,   8.,   0.,   0.,   4.,  11.,   0.,
         1.,  12.,   7.,   0.,   0.,   2.,  14.,   5.,  10.,  12.,   0.,
         0.,   0.,   0.,   6.,  13.,  10.,   0.,   0.,   0.])
</code></pre><h3 id="estimators-对象"><a href="#estimators-对象" class="headerlink" title="estimators 对象"></a>estimators 对象</h3><p>estimator 是任何从数据中学习到的对象,可以是分类,回归,聚类或者是一个 transformer 从原始数据中提取(extracts)/过滤(filters)特征.</p>
<p>所有 estimator 有 <code>fit</code> 方法</p>
<p><code>python
estimator.fit(data)</code></p>
<p><strong>Estimator parameters</strong>:所有estimator的参数可以在初始化时设置并用attribute修改:</p>
<p><code>python
estimator = Estimator(param1=1, param2=2)
estimator.param1</code></p>
<p><strong>Estimator parameters</strong>:当数据拟合后,参数被估计,所有估计的参数是estimator的一个属性,用如下下划线表示</p>
<p><code>python
estimator.estimated_param_</code></p>
<h2 id="2-监督学习"><a href="#2-监督学习" class="headerlink" title="2. 监督学习"></a>2. 监督学习</h2><h3 id="最近邻和维度灾难"><a href="#最近邻和维度灾难" class="headerlink" title="最近邻和维度灾难"></a>最近邻和维度灾难</h3><p>iris 数据集是一个分类任务,包括3个不同的irises类</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line">iris = datasets.load_iris()</span><br><span class="line">iris_X = iris.data</span><br><span class="line">iris_y = iris.target</span><br><span class="line">np.unique(iris_y)</span><br></pre></td></tr></table></figure>
<pre><code>array([0, 1, 2])
</code></pre><h3 id="KNN分类"><a href="#KNN分类" class="headerlink" title="KNN分类"></a>KNN分类</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># split iris data in train and test data</span></span><br><span class="line"><span class="comment"># A random permutation, to split the data randomly</span></span><br><span class="line">np.random.seed(<span class="number">0</span>)</span><br><span class="line">indices = np.random.permutation(len(iris_X))</span><br><span class="line">iris_X_train = iris_X[indices[:<span class="number">-10</span>]]</span><br><span class="line">iris_y_train = iris_y[indices[:<span class="number">-10</span>]]</span><br><span class="line">iris_X_test = iris_X[indices[<span class="number">-10</span>:]]</span><br><span class="line">iris_y_test = iris_y[indices[<span class="number">-10</span>:]]</span><br><span class="line"><span class="comment"># Create and fit a nearest-neighbor classifier</span></span><br><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line">knn = KNeighborsClassifier()</span><br><span class="line">knn.fit(iris_X_train, iris_y_train)</span><br></pre></td></tr></table></figure>
<pre><code>KNeighborsClassifier(algorithm=&apos;auto&apos;, leaf_size=30, metric=&apos;minkowski&apos;,
           metric_params=None, n_jobs=1, n_neighbors=5, p=2,
           weights=&apos;uniform&apos;)
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">knn.predict(iris_X_test)</span><br></pre></td></tr></table></figure>
<pre><code>array([1, 2, 1, 0, 0, 0, 2, 1, 2, 0])
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">iris_y_test</span><br></pre></td></tr></table></figure>
<pre><code>array([1, 1, 1, 0, 0, 0, 2, 1, 2, 0])
</code></pre><h3 id="维度灾难"><a href="#维度灾难" class="headerlink" title="维度灾难"></a>维度灾难</h3><p>为了使学习器有效,你需要将邻居的距离小于一个值<code>d</code>.1维中,平均 <code>n ~ 1/d</code>个点.<br>如果特征数为<code>p</code>,你需要 <code>n ~ 1/d^p</code> 个点.例如1维中要求10个点,<code>p</code>维中就要求<code>10^p</code>个点.</p>
<h3 id="线性模型-从回归到稀疏"><a href="#线性模型-从回归到稀疏" class="headerlink" title="线性模型:从回归到稀疏"></a>线性模型:从回归到稀疏</h3><p><strong>Diabetes 数据集</strong></p>
<p>这个数据集包括442个病人的10个生理变量,和1年后的癌症迹象,任务是从生理变量中预测癌症</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">diabetes = datasets.load_diabetes()</span><br><span class="line">diabetes_X_train = diabetes.data[:<span class="number">-20</span>]</span><br><span class="line">diabetes_X_test = diabetes.data[<span class="number">-20</span>:]</span><br><span class="line">diabetes_y_train = diabetes.target[:<span class="number">-20</span>]</span><br><span class="line">diabetes_y_test = diabetes.target[<span class="number">-20</span>:]</span><br></pre></td></tr></table></figure>
<h3 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> linear_model</span><br><span class="line">regr = linear_model.LinearRegression()</span><br><span class="line">regr.fit(diabetes_X_train, diabetes_y_train)</span><br></pre></td></tr></table></figure>
<pre><code>LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(regr.coef_)</span><br></pre></td></tr></table></figure>
<pre><code>[  3.03499549e-01  -2.37639315e+02   5.10530605e+02   3.27736980e+02
  -8.14131709e+02   4.92814588e+02   1.02848452e+02   1.84606489e+02
   7.43519617e+02   7.60951722e+01]
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># The mean square error</span></span><br><span class="line">np.mean((regr.predict(diabetes_X_test) - diabetes_y_test)**<span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<pre><code>2004.5676026898225
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Explained variance score: 1 is perfect prediction</span></span><br><span class="line"><span class="comment"># and 0 means that there is no linear relationship</span></span><br><span class="line"><span class="comment"># between X and y.</span></span><br><span class="line">regr.score(diabetes_X_test, diabetes_y_test)</span><br></pre></td></tr></table></figure>
<pre><code>0.58507530226905713
</code></pre><h3 id="收缩-shrinkage"><a href="#收缩-shrinkage" class="headerlink" title="收缩(shrinkage)"></a>收缩(shrinkage)</h3><blockquote>
<p>通过对损失函数(即优化目标)加入惩罚项，使得训练求解参数过程中会考虑到系数的大小，通过设置缩减系数(惩罚系数)，会使得影响较小的特征的系数衰减到0，只保留重要的特征。常用的缩减系数方法有lasso(L1正则化)，岭回归(L2正则化)。</p>
</blockquote>
<p>如果每个维度的数据点很少，观察噪声就会导致很大的方差</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X = np.c_[ <span class="number">.5</span>, <span class="number">1</span>].T <span class="comment"># 按列组合</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">print(np.c_[ <span class="number">.5</span>, <span class="number">1</span>])</span><br><span class="line">print(X)</span><br></pre></td></tr></table></figure>
<pre><code>[[ 0.5  1. ]]
[[ 0.5]
 [ 1. ]]
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br><span class="line">y = [<span class="number">0.5</span>, <span class="number">1</span>]</span><br><span class="line">test = np.c_[<span class="number">0</span>, <span class="number">2</span>].T</span><br><span class="line">regr = linear_model.LinearRegression()</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.figure()</span><br><span class="line"></span><br><span class="line">np.random.seed(<span class="number">0</span>)</span><br><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> range(<span class="number">6</span>):</span><br><span class="line">    this_X = <span class="number">0.1</span> * np.random.normal(size=(<span class="number">2</span>, <span class="number">1</span>)) + X</span><br><span class="line">    regr.fit(this_X, y)</span><br><span class="line">    plt.plot(test, regr.predict(test))</span><br><span class="line">    plt.scatter(this_X, y, s=<span class="number">3</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/image/scikit-learn/2/output_23_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">regr = linear_model.Ridge(alpha=<span class="number">0.1</span>)</span><br><span class="line">plt.figure()</span><br><span class="line">np.random.seed(<span class="number">0</span>)</span><br><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> range(<span class="number">6</span>):</span><br><span class="line">    this_X = <span class="number">0.1</span> * np.random.normal(size=(<span class="number">2</span>, <span class="number">1</span>)) + X</span><br><span class="line">    regr.fit(this_X, y)</span><br><span class="line">    plt.plot(test, regr.predict(test))</span><br><span class="line">    plt.scatter(this_X, y, s=<span class="number">3</span>)</span><br></pre></td></tr></table></figure>
<p><img src="/image/scikit-learn/2/output_24_0.png" alt="png"></p>
<p>这是一个 bias/variance 折衷的例子:<code>alpha</code>越大,bias越大,variance越小.我们选择 <code>alpha</code>来极小化输出误差.考虑数据集 diabetes</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">alphas = np.logspace(<span class="number">-4</span>, <span class="number">-1</span>, <span class="number">6</span>)</span><br><span class="line">print([regr.set_params(alpha=alpha</span><br><span class="line">            ).fit(diabetes_X_train, diabetes_y_train,</span><br><span class="line">            ).score(diabetes_X_test, diabetes_y_test) <span class="keyword">for</span> alpha <span class="keyword">in</span> alphas])</span><br></pre></td></tr></table></figure>
<pre><code>[0.58511106838835336, 0.58520730154446765, 0.5854677540698493, 0.58555120365039159, 0.58307170855541623, 0.57058999437280111]
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">alphas</span><br></pre></td></tr></table></figure>
<pre><code>array([ 0.0001    ,  0.00039811,  0.00158489,  0.00630957,  0.02511886,
        0.1       ])
</code></pre><h3 id="稀疏性"><a href="#稀疏性" class="headerlink" title="稀疏性"></a>稀疏性</h3><p>只拟合特征1和特征2</p>
<p><img src="/image/scikit-learn/2/1.png" alt=""></p>
<p>我们可以看到，尽管特征2在整个模型占有一个很大的系数，但是当考虑特征1时，其对 y 的影响就较小了。</p>
<p>为了改善问题条件,如缓解维度灾难,只选择部分提供信息的特征并将另一部分设置为无信息特征,例如特征2系数设为0.岭回归将会减小它的贡献,但不会设置为0.另一个惩罚方法称为<code>Lasso</code>,可以将一些系数设为0.这种方法称为稀疏方法,稀疏性可以视为 Occam 剃刀原则的应用.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">regr = linear_model.Lasso()</span><br><span class="line">scores = [regr.set_params(alpha=alpha</span><br><span class="line">            ).fit(diabetes_X_train, diabetes_y_train,</span><br><span class="line">            ).score(diabetes_X_test, diabetes_y_test) <span class="keyword">for</span> alpha <span class="keyword">in</span> alphas]</span><br><span class="line">best_alpha = alphas[scores.index(max(scores))]</span><br><span class="line">regr.alpha = best_alpha</span><br><span class="line">regr.fit(diabetes_X_train, diabetes_y_train)</span><br></pre></td></tr></table></figure>
<pre><code>Lasso(alpha=0.025118864315095794, copy_X=True, fit_intercept=True,
   max_iter=1000, normalize=False, positive=False, precompute=False,
   random_state=None, selection=&apos;cyclic&apos;, tol=0.0001, warm_start=False)
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(regr.coef_)</span><br></pre></td></tr></table></figure>
<pre><code>[   0.         -212.43764548  517.19478111  313.77959962 -160.8303982    -0.
 -187.19554705   69.38229038  508.66011217   71.84239008]
</code></pre><p><strong>Notes</strong>:scikit-learn 也提供 <code>LassoLars</code> 使用 LARS 算法,对权重向量稀疏的时候很有效.</p>
<h3 id="分类"><a href="#分类" class="headerlink" title="分类"></a>分类</h3><p>在 iris 任务中,线性回归不是一个正确的方法,它给较远的数据给了太大的权重.另一个线性方法是用 sigmoid 函数或 logistic 函数</p>
<p><img src="/image/scikit-learn/2/2.png" alt=""><br><img src="/image/scikit-learn/2/3.png" alt=""></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">logistic = linear_model.LogisticRegression(C=<span class="number">1e5</span>)</span><br><span class="line">logistic.fit(iris_X_train, iris_y_train)</span><br></pre></td></tr></table></figure>
<pre><code>LogisticRegression(C=100000.0, class_weight=None, dual=False,
          fit_intercept=True, intercept_scaling=1, max_iter=100,
          multi_class=&apos;ovr&apos;, n_jobs=1, penalty=&apos;l2&apos;, random_state=None,
          solver=&apos;liblinear&apos;, tol=0.0001, verbose=0, warm_start=False)
</code></pre><p><img src="/image/scikit-learn/2/4.png" alt=""></p>
<blockquote>
<p><strong>多分类</strong><br>如果你有很多类需要预测，一种常用方法就是去拟合一对多分类器，然后使用根据投票为最后做决定。</p>
</blockquote>
<blockquote>
<p><strong>logistic回归的收缩和稀疏性</strong><br>C 参数控制了正则化参数,C 越大正则化越小.<code>penalty=&#39;12&#39;</code>给出了收缩,<code>penalty=&#39;11&#39;</code>给出了稀疏性.</p>
</blockquote>
<blockquote>
<p><strong>练习</strong><br>尝试用最近邻与线性模型分类手写数字集,用最后10%测试</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets, neighbors, linear_model</span><br><span class="line"></span><br><span class="line">digits = datasets.load_digits()</span><br><span class="line">X_digits = digits.data</span><br><span class="line">y_digits = digits.target</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X_digits.shape</span><br></pre></td></tr></table></figure>
<pre><code>(1797, 64)
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">split = int(len(X_digits) * <span class="number">0.9</span>)</span><br><span class="line">X_digits_train = X_digits[:split]</span><br><span class="line">y_digits_train = y_digits[:split]</span><br><span class="line">X_digits_test = X_digits[split:]</span><br><span class="line">y_digits_test = y_digits[split:]</span><br><span class="line">knn = neighbors.KNeighborsClassifier()</span><br><span class="line">knn.fit(X_digits_train, y_digits_train)</span><br></pre></td></tr></table></figure>
<pre><code>KNeighborsClassifier(algorithm=&apos;auto&apos;, leaf_size=30, metric=&apos;minkowski&apos;,
           metric_params=None, n_jobs=1, n_neighbors=5, p=2,
           weights=&apos;uniform&apos;)
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'knn score: %f'</span> % knn.score(X_digits_test, y_digits_test))</span><br></pre></td></tr></table></figure>
<pre><code>knn score: 0.961111
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">logistic = linear_model.LogisticRegression()</span><br><span class="line">logistic.fit(X_digits_train, y_digits_train)</span><br><span class="line">print(<span class="string">'logistic score: %f'</span> % logistic.score(X_digits_test, y_digits_test))</span><br></pre></td></tr></table></figure>
<pre><code>logistic score: 0.938889
</code></pre><h3 id="SVM"><a href="#SVM" class="headerlink" title="SVM"></a>SVM</h3><h3 id="线性-SVM"><a href="#线性-SVM" class="headerlink" title="线性 SVM"></a>线性 SVM</h3><p>SVM 属于判别模型,它试图找到样本的组合来建立一个超平面来极大化类别间的 margin.正则化由<code>C</code>参数设置,小的<code>C</code>意味着边缘是通过分割线周围的所有观测样例进行计算得到的(更大正则化)；大的<code>C</code>意味着边缘是通过邻近分割线的观测样例计算得到的(更少正则化)。</p>
<p><img src="/image/scikit-learn/2/5.png" alt=""></p>
<p>SVM 可用于回归 SVR,分类 SVC</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> svm</span><br><span class="line">svc = svm.SVC(kernel=<span class="string">'linear'</span>)</span><br><span class="line">svc.fit(iris_X_train, iris_y_train)</span><br></pre></td></tr></table></figure>
<pre><code>SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,
  decision_function_shape=&apos;ovr&apos;, degree=3, gamma=&apos;auto&apos;, kernel=&apos;linear&apos;,
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False)
</code></pre><h3 id="使用核"><a href="#使用核" class="headerlink" title="使用核"></a>使用核</h3><p>对于线性不可分的类使用核技巧.例如换成多项式核</p>
<p><img src="/image/scikit-learn/2/6.png" alt=""></p>
<p>RBF核</p>
<p><img src="/image/scikit-learn/2/7.png" alt=""></p>
<p><a href="http://sklearn.apachecn.org/cn/0.19.0/auto_examples/applications/svm_gui.html#sphx-glr-auto-examples-applications-svm-gui-py" target="_blank" rel="noopener">交互式的例子</a></p>
<p><img src="/image/scikit-learn/2/8.png" alt=""></p>
<h3 id="练习"><a href="#练习" class="headerlink" title="练习"></a>练习</h3><p>根据特征1和特征2，尝试用 SVMs 把1和2类从鸢尾属植物数据集中分出来。为每一个类留下10%，并测试这些观察值预期效果。</p>
<p><strong>Warning</strong>:类已排序,不能直接用后10%<br><strong>hint</strong>: 为了直观显示，你可以在网格上使用 <code>decision_function</code> 方法</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">iris = datasets.load_iris()</span><br><span class="line">X = iris.data</span><br><span class="line">y = iris.target</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X = X[y != <span class="number">0</span>, :<span class="number">2</span>]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">y = y[y != <span class="number">0</span>]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">np.random.seed(<span class="number">0</span>)</span><br><span class="line">indices = np.random.permutation(len(X))</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">split = int(len(X) * <span class="number">0.9</span>)</span><br><span class="line">X_train = X[indices[:split]]</span><br><span class="line">y_train = y[indices[:split]]</span><br><span class="line">X_test = X[indices[split:]]</span><br><span class="line">y_test = y[indices[split:]]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> fig_num, kernel <span class="keyword">in</span> enumerate((<span class="string">'linear'</span>, <span class="string">'rbf'</span>, <span class="string">'poly'</span>)):</span><br><span class="line">    clf = svm.SVC(kernel=kernel, gamma=<span class="number">10</span>)</span><br><span class="line">    clf.fit(X_train, y_train)</span><br><span class="line">    </span><br><span class="line">    plt.figure(fig_num)</span><br><span class="line">    plt.clf()</span><br><span class="line">    <span class="comment"># 散点图颜色c根据类别y上色,绘图样式选择paired,zorder绘图顺序</span></span><br><span class="line">    plt.scatter(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], c=y, zorder=<span class="number">10</span>, cmap=plt.cm.Paired,</span><br><span class="line">               edgecolor=<span class="string">'k'</span>, s=<span class="number">20</span>) </span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Circle out the test data</span></span><br><span class="line">    plt.scatter(X_test[:, <span class="number">0</span>], X_test[:, <span class="number">1</span>], s=<span class="number">80</span>, facecolors=<span class="string">'none'</span>,</span><br><span class="line">               zorder=<span class="number">10</span>, edgecolor=<span class="string">'k'</span>)</span><br><span class="line">    plt.axis(<span class="string">'tight'</span>)</span><br><span class="line">    x_min = X[:, <span class="number">0</span>].min()</span><br><span class="line">    x_max = X[:, <span class="number">0</span>].max()</span><br><span class="line">    y_min = X[:, <span class="number">1</span>].min()</span><br><span class="line">    y_max = X[:, <span class="number">1</span>].max()</span><br><span class="line">    </span><br><span class="line">    XX, YY = np.mgrid[x_min:x_max:<span class="number">200j</span>, y_min:y_max:<span class="number">200j</span>]</span><br><span class="line">    <span class="comment"># ravel 拉直</span></span><br><span class="line">    Z = clf.decision_function(np.c_[XX.ravel(), YY.ravel()]) </span><br><span class="line">    </span><br><span class="line">    <span class="comment"># Put the result into a color plot</span></span><br><span class="line">    Z = Z.reshape(XX.shape)</span><br><span class="line">    plt.pcolormesh(XX, YY, Z &gt; <span class="number">0</span>, cmap=plt.cm.Paired)</span><br><span class="line">    plt.contour(XX, YY, Z, colors=[<span class="string">'k'</span>, <span class="string">'k'</span>, <span class="string">'k'</span>], </span><br><span class="line">               linestyles=[<span class="string">'--'</span>, <span class="string">'-'</span>, <span class="string">'--'</span>], levels=[<span class="number">-0.5</span>, <span class="number">0</span>, <span class="number">0.5</span>])</span><br><span class="line">    plt.title(kernel)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/image/scikit-learn/2/output_47_0.png" alt="png"></p>
<p><img src="/image/scikit-learn/2/output_47_1.png" alt="png"></p>
<p><img src="/image/scikit-learn/2/output_47_2.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">XX, YY = np.mgrid[x_min:x_max:<span class="number">200j</span>, y_min:y_max:<span class="number">200j</span>]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">len(XX), len(YY)</span><br></pre></td></tr></table></figure>
<pre><code>(200, 200)
</code></pre><h2 id="模型选择-选择-estimators-与参数"><a href="#模型选择-选择-estimators-与参数" class="headerlink" title="模型选择: 选择 estimators 与参数"></a>模型选择: 选择 estimators 与参数</h2><h3 id="分数与交叉验证分数"><a href="#分数与交叉验证分数" class="headerlink" title="分数与交叉验证分数"></a>分数与交叉验证分数</h3><p>每一个 estimator 有一个 <code>score</code> 方法,在新数据上判定拟合或预测的质量.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets, svm</span><br><span class="line">digits = datasets.load_digits()</span><br><span class="line">X_digits = digits.data</span><br><span class="line">y_digits = digits.target</span><br><span class="line">svc = svm.SVC(C=<span class="number">1</span>, kernel=<span class="string">'linear'</span>)</span><br><span class="line">svc.fit(X_digits[:<span class="number">-100</span>], y_digits[:<span class="number">-100</span>]).score(X_digits[<span class="number">-100</span>:], y_digits[<span class="number">-100</span>:])</span><br></pre></td></tr></table></figure>
<pre><code>0.97999999999999998
</code></pre><p>为了更好地刻画预测精度,我们用<code>KFold</code>交叉验证</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">X_folds = np.array_split(X_digits, <span class="number">3</span>)</span><br><span class="line">y_folds = np.array_split(y_digits, <span class="number">3</span>)</span><br><span class="line">scores = list()</span><br><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> range(<span class="number">3</span>):</span><br><span class="line">    <span class="comment"># We use 'list' to copy, in order to 'pop' later on</span></span><br><span class="line">    X_train = list(X_folds)</span><br><span class="line">    X_test = X_train.pop(k)</span><br><span class="line">    X_train = np.concatenate(X_train) <span class="comment"># 合并为一个list</span></span><br><span class="line">    y_train = list(y_folds)</span><br><span class="line">    y_test = y_train.pop(k)</span><br><span class="line">    y_train = np.concatenate(y_train)</span><br><span class="line">    scores.append(svc.fit(X_train, y_train).score(X_test, y_test))</span><br><span class="line">print(scores)</span><br></pre></td></tr></table></figure>
<pre><code>[0.93489148580968284, 0.95659432387312182, 0.93989983305509184]
</code></pre><h3 id="交叉验证生成器"><a href="#交叉验证生成器" class="headerlink" title="交叉验证生成器"></a>交叉验证生成器</h3><p>scikit-learn 有生成训练/测试下标list的类来进行交叉验证<br>它用split方法,接受输入数据集,并分成训练/测试集的下标,在每一次迭代中选择相应的交叉验证策略</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> KFold, cross_val_score</span><br><span class="line">X = [<span class="string">'a'</span>, <span class="string">'a'</span>, <span class="string">'b'</span>, <span class="string">'c'</span>, <span class="string">'c'</span>, <span class="string">'c'</span>]</span><br><span class="line">k_fold = KFold(n_splits=<span class="number">3</span>)</span><br><span class="line"><span class="keyword">for</span> train_indices, test_indices <span class="keyword">in</span> k_fold.split(X):</span><br><span class="line">    print(<span class="string">'Train: %s | test: %s'</span> % (train_indices, test_indices))</span><br></pre></td></tr></table></figure>
<pre><code>Train: [2 3 4 5] | test: [0 1]
Train: [0 1 4 5] | test: [2 3]
Train: [0 1 2 3] | test: [4 5]
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[svc.fit(X_digits[train], y_digits[train]).score(X_digits[test], y_digits[test])</span><br><span class="line"><span class="keyword">for</span> train, test <span class="keyword">in</span> k_fold.split(X_digits)]</span><br></pre></td></tr></table></figure>
<pre><code>[0.93489148580968284, 0.95659432387312182, 0.93989983305509184]
</code></pre><p>交叉验证分数可以直接使用 <code>cross_val_score</code> 计算.<br>默认的 estimator 的 <code>score</code> 计算的是独立的分数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cross_val_score(svc, X_digits, y_digits, cv=k_fold, n_jobs=<span class="number">-1</span>)</span><br></pre></td></tr></table></figure>
<pre><code>array([ 0.93489149,  0.95659432,  0.93989983])
</code></pre><p><code>n_jobs=-1</code> 表示计算会被分配到所有的 CPU 中<br>或者提供 <code>scoring</code> 参数来提供一个替代的评分方法</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cross_val_score(svc, X_digits, y_digits, cv=k_fold, </span><br><span class="line">                scoring=<span class="string">'precision_macro'</span>)</span><br></pre></td></tr></table></figure>
<pre><code>array([ 0.93969761,  0.95911415,  0.94041254])
</code></pre><p><strong>交叉验证生成器</strong></p>
<table>
<thead>
<tr>
<th>KFold(n_splits, shuffle, random_state)</th>
<th>StratifiedKFold(n_splits, shuffle, random_state)</th>
<th>GroupKFold (n_splits)</th>
</tr>
</thead>
<tbody>
<tr>
<td>分成k折,在k-1上训练,最后一个测试</td>
<td>保留了每个折里的类分布</td>
<td>确保相同组不会同时在训练集和测试集</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th>ShuffleSplit(n_splits, test_size, train_size, random_state)</th>
<th>StratifiedShuffleSplit</th>
<th>GroupShuffleSplit</th>
</tr>
</thead>
<tbody>
<tr>
<td>随机</td>
<td>随机,保留了每个折里的类分布</td>
<td>确保相同组不会同时在训练集和测试集</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th>LeaveOneGroupOut()</th>
<th>LeavePGroupsOut(n_groups)</th>
<th>LeaveOneOut()</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th>LeavePOut(p)</th>
<th>PredefinedSplit</th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
</tr>
</tbody>
</table>
<h3 id="练习-1"><a href="#练习-1" class="headerlink" title="练习"></a>练习</h3><p><img src="/image/scikit-learn/2/9.png" alt=""></p>
<p>在数字数据集中，绘制关于线性核的 SVC estimator交叉验证分数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets, svm</span><br><span class="line"></span><br><span class="line">digits = datasets.load_digits()</span><br><span class="line">X = digits.data</span><br><span class="line">y = digits.target</span><br><span class="line"></span><br><span class="line">svc = svm.SVC(kernel=<span class="string">'linear'</span>)</span><br><span class="line">C_s = np.logspace(<span class="number">-10</span>, <span class="number">0</span>, <span class="number">10</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">scores_mean = []</span><br><span class="line">scores_std = []</span><br><span class="line"><span class="keyword">for</span> C <span class="keyword">in</span> C_s:</span><br><span class="line">    svc.C = C</span><br><span class="line">    score = cross_val_score(svc, X, y, n_jobs=<span class="number">1</span>)</span><br><span class="line">    scores_mean.append(np.mean(score))</span><br><span class="line">    scores_std.append(np.std(score))</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Do the plotting</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.figure(<span class="number">1</span>, figsize=(<span class="number">4</span>, <span class="number">3</span>))</span><br><span class="line">plt.clf()</span><br><span class="line">plt.semilogx(C_s, scores_mean)</span><br><span class="line">plt.semilogx(C_s, np.array(scores_mean) + np.array(scores_std), <span class="string">'b--'</span>)</span><br><span class="line">plt.semilogx(C_s, np.array(scores_mean) - np.array(scores_std), <span class="string">'b--'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'CV score'</span>)</span><br><span class="line">plt.xlabel(<span class="string">'Parameter C'</span>)</span><br><span class="line">plt.ylim(<span class="number">0</span>, <span class="number">1.1</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="/image/scikit-learn/2/output_65_0.png" alt="png"></p>
<h3 id="网格搜索与交叉验证-estimator"><a href="#网格搜索与交叉验证-estimator" class="headerlink" title="网格搜索与交叉验证 estimator"></a>网格搜索与交叉验证 estimator</h3><h3 id="网格搜索"><a href="#网格搜索" class="headerlink" title="网格搜索"></a>网格搜索</h3><p>scikit-learn 提供对象通过给定数据计算在参数网格拟合estimator时的分数来最大化交叉验证分数.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV, cross_val_score</span><br><span class="line">Cs = np.logspace(<span class="number">-6</span>, <span class="number">-1</span>, <span class="number">10</span>)</span><br><span class="line">clf = GridSearchCV(estimator=svc, param_grid=dict(C=Cs), n_jobs=<span class="number">-1</span>)</span><br><span class="line">clf.fit(X_digits[:<span class="number">1000</span>], y_digits[:<span class="number">1000</span>])</span><br></pre></td></tr></table></figure>
<pre><code>GridSearchCV(cv=None, error_score=&apos;raise&apos;,
       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,
  decision_function_shape=&apos;ovr&apos;, degree=3, gamma=&apos;auto&apos;, kernel=&apos;linear&apos;,
  max_iter=-1, probability=False, random_state=None, shrinking=True,
  tol=0.001, verbose=False),
       fit_params=None, iid=True, n_jobs=-1,
       param_grid={&apos;C&apos;: array([  1.00000e-06,   3.59381e-06,   1.29155e-05,   4.64159e-05,
         1.66810e-04,   5.99484e-04,   2.15443e-03,   7.74264e-03,
         2.78256e-02,   1.00000e-01])},
       pre_dispatch=&apos;2*n_jobs&apos;, refit=True, return_train_score=&apos;warn&apos;,
       scoring=None, verbose=0)
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">clf.best_score_</span><br></pre></td></tr></table></figure>
<pre><code>0.92500000000000004
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">clf.best_estimator_.C</span><br></pre></td></tr></table></figure>
<pre><code>0.0077426368268112772
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">clf.score(X_digits[<span class="number">1000</span>:], y_digits[<span class="number">1000</span>:])</span><br></pre></td></tr></table></figure>
<pre><code>0.94353826850690092
</code></pre><p>默认 <code>GridSearchCV</code> 使用3折交叉验证,但如果是分类而不是回归,则使用stratified 3折<br>交叉验证 estimators</p>
<p>设置参数的交叉验证可以更有效地完成一个基础算法。这就是为什么对某些估计量来说，scikit-learn 提供了 交叉验证 估计量自动设置它们的参数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> linear_model, datasets</span><br><span class="line">lasso = linear_model.LassoCV()</span><br><span class="line">diabetes = datasets.load_diabetes()</span><br><span class="line">X_diabetes = diabetes.data</span><br><span class="line">y_diabetes = diabetes.target</span><br><span class="line">lasso.fit(X_diabetes, y_diabetes)</span><br></pre></td></tr></table></figure>
<pre><code>LassoCV(alphas=None, copy_X=True, cv=None, eps=0.001, fit_intercept=True,
    max_iter=1000, n_alphas=100, n_jobs=1, normalize=False, positive=False,
    precompute=&apos;auto&apos;, random_state=None, selection=&apos;cyclic&apos;, tol=0.0001,
    verbose=False)
</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">lasso.alpha_</span><br></pre></td></tr></table></figure>
<pre><code>0.012291895087486161
</code></pre><h3 id="练习-2"><a href="#练习-2" class="headerlink" title="练习"></a>练习</h3><p>在 diabetes 数据集中,找到最优的正则化参数 alpha<br>另外： 你有多相信 alpha 的选择？</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> LassoCV</span><br><span class="line"><span class="keyword">from</span> sklearn.linear_model <span class="keyword">import</span> Lasso</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> KFold</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV</span><br><span class="line"></span><br><span class="line">diabetes = datasets.load_diabetes()</span><br><span class="line"></span><br><span class="line">X = diabetes.data[:<span class="number">150</span>]</span><br><span class="line">y = diabetes.target[:<span class="number">150</span>]</span><br><span class="line"></span><br><span class="line">lasso = Lasso(random_state=<span class="number">0</span>)</span><br><span class="line">alphas = np.logspace(<span class="number">-4</span>, <span class="number">-0.5</span>, <span class="number">30</span>)</span><br><span class="line"></span><br><span class="line">tuned_parameters = [&#123;<span class="string">'alpha'</span>: alphas&#125;]</span><br><span class="line">n_folds = <span class="number">3</span></span><br><span class="line"></span><br><span class="line">clf = GridSearchCV(lasso, tuned_parameters, cv=n_folds, refit=<span class="keyword">False</span>)</span><br><span class="line">clf.fit(X, y)</span><br><span class="line">scores = clf.cv_results_[<span class="string">'mean_test_score'</span>]</span><br><span class="line">scores_std = clf.cv_results_[<span class="string">'std_test_score'</span>]</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">plt.figure().set_size_inches(<span class="number">8</span>, <span class="number">6</span>)</span><br><span class="line">plt.semilogx(alphas, scores)</span><br><span class="line"></span><br><span class="line"><span class="comment">#plot error lines showing +/- std. error of the scores</span></span><br><span class="line">std_error = scores_std / np.sqrt(n_folds)</span><br><span class="line"></span><br><span class="line">plt.semilogx(alphas, scores + std_error, <span class="string">'b--'</span>)</span><br><span class="line">plt.semilogx(alphas, scores - std_error, <span class="string">'b--'</span>)</span><br><span class="line"><span class="comment"># alpha=0.2 controls the translucency of the fill color</span></span><br><span class="line">plt.fill_between(alphas, scores + std_error, scores - std_error, alpha=<span class="number">0.2</span>)</span><br><span class="line">plt.ylabel(<span class="string">'CV score +/- std error'</span>)</span><br><span class="line">plt.xlabel(<span class="string">'alpha'</span>)</span><br><span class="line">plt.axhline(np.max(scores), linestyle=<span class="string">'--'</span>, color=<span class="string">'.5'</span>)</span><br><span class="line">plt.xlim([alphas[<span class="number">0</span>], alphas[<span class="number">-1</span>]])</span><br></pre></td></tr></table></figure>
<pre><code>(0.0001, 0.31622776601683794)
</code></pre><p><img src="/image/scikit-learn/2/output_76_1.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># #############################################################################</span></span><br><span class="line"><span class="comment"># Bonus: how much can you trust the selection of alpha?</span></span><br><span class="line"><span class="comment"># To answer this question we use the LassoCV object that sets its alpha</span></span><br><span class="line"><span class="comment"># parameter automatically from the data by internal cross-validation (i.e. it</span></span><br><span class="line"><span class="comment"># performs cross-validation on the training data it receives).</span></span><br><span class="line"><span class="comment"># We use external cross-validation to see how much the automatically obtained</span></span><br><span class="line"><span class="comment"># alphas differ across different cross-validation folds.</span></span><br><span class="line"></span><br><span class="line">lasso_cv = LassoCV(alphas=alphas, random_state=<span class="number">0</span>)</span><br><span class="line">k_fold = KFold(<span class="number">3</span>)</span><br><span class="line">print(<span class="string">"Answer to the bonus question:"</span>,</span><br><span class="line"><span class="string">"how much can you trust the selection of alpha?"</span>)</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">"Alpha parameters maximising the generalization score on different"</span>)</span><br><span class="line">print(<span class="string">"subsets of the data:"</span>)</span><br><span class="line"><span class="keyword">for</span> k, (train, test) <span class="keyword">in</span> enumerate(k_fold.split(X)):</span><br><span class="line">    lasso_cv.fit(X[train], y[train])</span><br><span class="line">    print(<span class="string">"[fold &#123;0&#125;] alpha: &#123;1:.5f&#125;, score: &#123;2:.5f&#125;"</span>.</span><br><span class="line">        format(k, lasso_cv.alpha_, lasso_cv.score(X[test], y[test])))</span><br><span class="line">print()</span><br><span class="line">print(<span class="string">"Answer: Not very much since we obtained different alphas for different"</span>)</span><br><span class="line">print(<span class="string">"subsets of the data and moreover, the scores for these alphas differ"</span>)</span><br><span class="line">print(<span class="string">"quite substantially."</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Answer to the bonus question: how much can you trust the selection of alpha?

Alpha parameters maximising the generalization score on different
subsets of the data:
[fold 0] alpha: 0.10405, score: 0.53573
[fold 1] alpha: 0.05968, score: 0.16278
[fold 2] alpha: 0.10405, score: 0.44437

Answer: Not very much since we obtained different alphas for different
subsets of the data and moreover, the scores for these alphas differ
quite substantially.
</code></pre>
        
        </div>
        <footer class="article-footer">
            <div class="share-container">



</div>

    <a data-url="http://zc119.github.io/2018/01/05/scikit-learn-学习-二-科学数据处理中的统计学习教程-上/" data-id="cjqlzsbo700204lihz10fib5u" class="article-share-link"><i class="fa fa-share"></i>分享到</a>
<script>
    (function ($) {
        // Prevent duplicate binding
        if (typeof(__SHARE_BUTTON_BINDED__) === 'undefined' || !__SHARE_BUTTON_BINDED__) {
            __SHARE_BUTTON_BINDED__ = true;
        } else {
            return;
        }
        $('body').on('click', function() {
            $('.article-share-box.on').removeClass('on');
        }).on('click', '.article-share-link', function(e) {
            e.stopPropagation();

            var $this = $(this),
                url = $this.attr('data-url'),
                encodedUrl = encodeURIComponent(url),
                id = 'article-share-box-' + $this.attr('data-id'),
                offset = $this.offset(),
                box;

            if ($('#' + id).length) {
                box = $('#' + id);

                if (box.hasClass('on')){
                    box.removeClass('on');
                    return;
                }
            } else {
                var html = [
                    '<div id="' + id + '" class="article-share-box">',
                        '<input class="article-share-input" value="' + url + '">',
                        '<div class="article-share-links">',
                            '<a href="https://twitter.com/intent/tweet?url=' + encodedUrl + '" class="fa fa-twitter article-share-twitter" target="_blank" title="Twitter"></a>',
                            '<a href="https://www.facebook.com/sharer.php?u=' + encodedUrl + '" class="fa fa-facebook article-share-facebook" target="_blank" title="Facebook"></a>',
                            '<a href="http://pinterest.com/pin/create/button/?url=' + encodedUrl + '" class="fa fa-pinterest article-share-pinterest" target="_blank" title="Pinterest"></a>',
                            '<a href="https://plus.google.com/share?url=' + encodedUrl + '" class="fa fa-google article-share-google" target="_blank" title="Google+"></a>',
                        '</div>',
                    '</div>'
                ].join('');

              box = $(html);

              $('body').append(box);
            }

            $('.article-share-box.on').hide();

            box.css({
                top: offset.top + 25,
                left: offset.left
            }).addClass('on');

        }).on('click', '.article-share-box', function (e) {
            e.stopPropagation();
        }).on('click', '.article-share-box-input', function () {
            $(this).select();
        }).on('click', '.article-share-box-link', function (e) {
            e.preventDefault();
            e.stopPropagation();

            window.open(this.href, 'article-share-box-window-' + Date.now(), 'width=500,height=450');
        });
    })(jQuery);
</script>

            
    

        </footer>
    </div>
    
        
<nav id="article-nav">
    
        <a href="/2018/01/06/scikit-learn-学习（二）科学数据处理中的统计学习教程-下/" id="article-nav-newer" class="article-nav-link-wrap">
            <strong class="article-nav-caption">上一篇</strong>
            <div class="article-nav-title">
                
                    scikit-learn 学习（二）科学数据处理中的统计学习教程 (下)
                
            </div>
        </a>
    
    
        <a href="/2018/01/04/scikit-learn-学习（一）介绍与安装/" id="article-nav-older" class="article-nav-link-wrap">
            <strong class="article-nav-caption">下一篇</strong>
            <div class="article-nav-title">scikit-learn 学习（一）介绍与安装</div>
        </a>
    
</nav>


    
</article>


    
    

</section>
            
                
<aside id="sidebar">
   
        
    <div class="widget-wrap">
        <h3 class="widget-title">最新文章</h3>
        <div class="widget">
            <ul id="recent-post" class="no-thumbnail">
                
                    <li>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/linux/">linux</a></p>
                            <p class="item-title"><a href="/2019/01/07/Docker实践/" class="title">Docker实践</a></p>
                            <p class="item-date"><time datetime="2019-01-07T07:13:17.000Z" itemprop="datePublished">2019-01-07</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/c/">c++</a></p>
                            <p class="item-title"><a href="/2018/12/24/MAKEFILE/" class="title">TopologySmooth 项目 Makefile 编译</a></p>
                            <p class="item-date"><time datetime="2018-12-24T12:25:05.000Z" itemprop="datePublished">2018-12-24</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/TensorFlow-实战/">TensorFlow 实战</a></p>
                            <p class="item-title"><a href="/2018/01/28/TensorFlow-实现卷积神经网络/" class="title">TensorFlow 实现卷积神经网络</a></p>
                            <p class="item-date"><time datetime="2018-01-28T12:42:20.000Z" itemprop="datePublished">2018-01-28</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/TensorFlow-实战/">TensorFlow 实战</a></p>
                            <p class="item-title"><a href="/2018/01/28/TensorFlow-实现自编码器及多层感知机/" class="title">TensorFlow 实现自编码器及多层感知机</a></p>
                            <p class="item-date"><time datetime="2018-01-28T01:55:14.000Z" itemprop="datePublished">2018-01-28</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/TensorFlow-实战/">TensorFlow 实战</a></p>
                            <p class="item-title"><a href="/2018/01/27/Tensorflow-第一步/" class="title">TensorFlow 第一步</a></p>
                            <p class="item-date"><time datetime="2018-01-27T05:58:51.000Z" itemprop="datePublished">2018-01-27</time></p>
                        </div>
                    </li>
                
            </ul>
        </div>
    </div>

    
        
    <div class="widget-wrap">
        <h3 class="widget-title">分类</h3>
        <div class="widget">
            <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/TensorFlow/">TensorFlow</a><span class="category-list-count">14</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/TensorFlow-实战/">TensorFlow 实战</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/c/">c++</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/data-analysis/">data analysis</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/linux/">linux</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/python-scraper/">python scraper</a><span class="category-list-count">12</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/scikit-learn/">scikit-learn</a><span class="category-list-count">8</span></li></ul>
        </div>
    </div>

    
        
    <div class="widget-wrap">
        <h3 class="widget-title">归档</h3>
        <div class="widget">
            <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/01/">一月 2019</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/12/">十二月 2018</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/01/">一月 2018</a><span class="archive-list-count">13</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/12/">十二月 2017</a><span class="archive-list-count">27</span></li></ul>
        </div>
    </div>

    
        
    <div class="widget-wrap">
        <h3 class="widget-title">标签</h3>
        <div class="widget">
            <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/TensorFlow/">TensorFlow</a><span class="tag-list-count">14</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/TensorFlow-实战/">TensorFlow 实战</a><span class="tag-list-count">4</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/c/">c++</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/data-analysis/">data analysis</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/linux/">linux</a><span class="tag-list-count">1</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/python-scraper/">python scraper</a><span class="tag-list-count">12</span></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/scikit-learn/">scikit-learn</a><span class="tag-list-count">8</span></li></ul>
        </div>
    </div>

    
        
    <div class="widget-wrap">
        <h3 class="widget-title">标签云</h3>
        <div class="widget tagcloud">
            <a href="/tags/TensorFlow/" style="font-size: 20px;">TensorFlow</a> <a href="/tags/TensorFlow-实战/" style="font-size: 12.5px;">TensorFlow 实战</a> <a href="/tags/c/" style="font-size: 10px;">c++</a> <a href="/tags/data-analysis/" style="font-size: 10px;">data analysis</a> <a href="/tags/linux/" style="font-size: 10px;">linux</a> <a href="/tags/python-scraper/" style="font-size: 17.5px;">python scraper</a> <a href="/tags/scikit-learn/" style="font-size: 15px;">scikit-learn</a>
        </div>
    </div>

    
        
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">链接</h3>
        <div class="widget">
            <ul>
                
                    <li>
                        <a href="http://hexo.io">Hexo</a>
                    </li>
                
            </ul>
        </div>
    </div>


    
    <div id="toTop" class="fa fa-angle-up"></div>
</aside>

            
        </div>
        <footer id="footer">
    <div class="outer">
        <div id="footer-info" class="inner">
            &copy; 2019 Chi Zhou<br>
            Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>. Theme by <a href="http://github.com/ppoffice">PPOffice</a>
        </div>
    </div>
</footer>
        


    
        <script src="/libs/lightgallery/js/lightgallery.min.js"></script>
        <script src="/libs/lightgallery/js/lg-thumbnail.min.js"></script>
        <script src="/libs/lightgallery/js/lg-pager.min.js"></script>
        <script src="/libs/lightgallery/js/lg-autoplay.min.js"></script>
        <script src="/libs/lightgallery/js/lg-fullscreen.min.js"></script>
        <script src="/libs/lightgallery/js/lg-zoom.min.js"></script>
        <script src="/libs/lightgallery/js/lg-hash.min.js"></script>
        <script src="/libs/lightgallery/js/lg-share.min.js"></script>
        <script src="/libs/lightgallery/js/lg-video.min.js"></script>
    
    
        <script src="/libs/justified-gallery/jquery.justifiedGallery.min.js"></script>
    
    



<!-- Custom Scripts -->
<script src="/js/main.js"></script>

    </div>
</body>
</html>